{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5855aab9",
   "metadata": {},
   "source": [
    "### Population inference example: BBH spin magnitude distribution\n",
    "\n",
    "This homework assignment will walk you through a simple example of hierarchical Bayesian inference using data from the first Gravitational-Wave Transient Catalog GWTC-1.\n",
    "\n",
    "We will assume that black hole spin magnitudes are drawn from a *beta distribution $\\beta(a,b)$* (which conveniently has support between 0 and 1, the physical range for black hole spin magnitudes). We will fix the parameter $a = 1$ and infer a single population parameter: the $b$ parameter of the beta distribution.\n",
    "\n",
    "For simplicity, we will neglect gravitational-wave selection effects (which do not strongly depend on spin magnitudes). \n",
    "\n",
    "Because our posterior is one-dimensional, we can evaluate the posterior probability density function on a grid.\n",
    "\n",
    "This repository contains parameter estimation samples downloaded from https://dcc.ligo.org/LIGO-P1800370/public"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c115939",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import scipy.stats as ss\n",
    "\n",
    "from scipy.integrate import cumtrapz\n",
    "\n",
    "import glob\n",
    "\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9934ad60",
   "metadata": {},
   "source": [
    "#### Read in parameter estimation samples from GWTC-1 (first 10 BBHs).\n",
    "\n",
    "These parameter estimation samples are inferred with an \"interim\" prior that is flat in the spin magnitude.\n",
    "Therefore, the posterior on the spin magnitude for each event is proportional to the parameter estimation likelihood, and we can neglect the interim prior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3adcb4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of files containing the parameter estimation samples for all 10 BBH events\n",
    "PEfiles = glob.glob(\"GWTC-1_sample_release/*.hdf5\")\n",
    "\n",
    "#initialize empty lists to contain the spin magnitude PE samples for each event\n",
    "#spin1 is the primary BH's spin, spin2 is the secondary BH's spin in each binary\n",
    "spin1_allevents = []\n",
    "spin2_allevents = []\n",
    "\n",
    "#loop over events\n",
    "for fname in PEfiles:\n",
    "    \n",
    "    with h5py.File(fname, \"r\") as f:\n",
    "        \n",
    "        #read in each event's spin1 and spin2 posterior samples \n",
    "        spin1 = np.array(f[\"Overall_posterior\"][\"spin1\"])\n",
    "        spin2 = np.array(f[\"Overall_posterior\"][\"spin2\"])\n",
    "        \n",
    "        #append each event's posterior samples array to our lists\n",
    "        spin1_allevents.append(spin1)\n",
    "        spin2_allevents.append(spin2)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9655aee3",
   "metadata": {},
   "source": [
    "## Problem 1 (10 points):\n",
    "\n",
    "Plot the parameter estimation spin1 and spin2 posteriors for each event (make a normalized histogram of the parameter estimation samples)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a744674",
   "metadata": {},
   "outputs": [],
   "source": [
    "###make plot\n",
    "\n",
    "for spin1 in spin1_allevents:\n",
    "    \n",
    "    plt.hist(spin1, bins = 20, density = True, histtype = 'step')\n",
    "    \n",
    "###repeat for spin2\n",
    "\n",
    "#label x-axis\n",
    "\n",
    "#label y-axis\n",
    "\n",
    "#add plot title\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33df0405",
   "metadata": {},
   "source": [
    "#### Population model\n",
    "\n",
    "We consider a population model for BH spins $s_1$ and $s_2$ given by the following probability density function (defined as ```pop_pdf_s1s2``` below):\n",
    "\n",
    "$$p(s_1, s_2 | b) = \\beta(s_1 \\mid a = 1, b) \\times \\beta(s_2 \\mid a = 1, b)$$\n",
    "\n",
    "and $\\beta(x \\mid a, b)$ is the probability density function of a beta distribution with shape parameters a and b, evaluated at x.\n",
    "\n",
    "We can evaluate $\\beta(x \\mid a, b)$ using ```scipy.stats.beta.pdf(x, a, b)```\n",
    "\n",
    "Here, using the notation from lecture $s_1$ and $s_2$ make up $\\theta$, while $b$ plays the role of $\\Lambda$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5dccfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pop_pdf_s1s2(s1, s2, b):  \n",
    "    return ss.beta.pdf(s1, a = 1, b = b) * ss.beta.pdf(s2, a = 1, b = b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba624d38",
   "metadata": {},
   "source": [
    "## Problem 2 (10 points):  \n",
    "To understand how this population model behaves, plot $\\beta(x \\mid a = 1, b)$ versus $x$ for a few different values of $b$: $b = 1, 1.5, 3, 7$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22033e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = #complete\n",
    "\n",
    "for b in bs:\n",
    "    x = np.linspace(0, 1, 100)\n",
    "    y = ss.beta.pdf(x, a = , b = ) #complete\n",
    "    \n",
    "    plt.plot( , label = f'b = {b}') #complete\n",
    "    \n",
    "plt.legend(loc = 'best')\n",
    "\n",
    "#label x-axis\n",
    "\n",
    "#label y-axis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d55558",
   "metadata": {},
   "source": [
    "#### Hierarchical Bayesian likelihood: single event\n",
    "\n",
    "We are interested in fitting the parameter $b$ of our population model.\n",
    "\n",
    "As we discussed in class, for a single event with data $d_i$, the hierarchical Bayesian likelihood, assuming no selection effects, is:\n",
    "$$\n",
    "p(d_i \\mid b) = \\int p(d_i \\mid s_1, s_2)p(s_1, s_2 \\mid b) ds_1 ds_2\n",
    "$$\n",
    "\n",
    "As we also discussed in class, we can approximate the integral as an average over parameter estimation samples, which are draws from the likelihood (this is known as a *Monte Carlo integral*). Note that in general the parameter estimation samples are not drawn from the likelihood, but from the likelihood times a prior. However in this case the parameter-estimation prior is flat, so we can ignore it. In general we have to divide out by the parameter estimation prior.\n",
    "\n",
    "If we have $N_{PE,i}$ parameter estimation samples for event $i$, our estimate for its single-event likelihood is therefore:\n",
    "\n",
    "$$\n",
    "p(d_i \\mid b) \\approx \\frac{1}{N_{PE,i}} \\sum_j^{N_{PE, i}} p(s_1^j, s_2^j \\mid b)\n",
    "$$\n",
    "\n",
    "## Problem 3 (5 pts): \n",
    "Fill in the missing terms in the single-event log likelihood function below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c025169",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loglikelihood_onesystem(spin1_samples,spin2_samples, b):\n",
    "    \n",
    "    return np.log(np.mean(pop_pdf_s1s2(??, ??, ??))) #fill this out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7bb58cb",
   "metadata": {},
   "source": [
    "#### Hierarchical Bayesian likelihood: all events\n",
    "\n",
    "The full likelihood from all 10 of our events is the product of single-event likelihoods\n",
    "$$\n",
    "p(\\mathbf{d} \\mid b) = \\prod_i^{10} p(d_i \\mid b),\n",
    "$$\n",
    "\n",
    "meaning the full log-likelihood is the sum of the single-event log-likelihoods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32068ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loglikelihood_allsystems(b):\n",
    "    \n",
    "    nevents = len(spin1_allevents) #we know this is 10 because we have 10 events, but this way is more general\n",
    "    \n",
    "    logL = sum([loglikelihood_onesystem(spin1_allevents[i], spin2_allevents[i], b) for i in range(nevents)])\n",
    "    \n",
    "    return logL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e753b590",
   "metadata": {},
   "source": [
    "## Problem 4 (10 points):\n",
    "\n",
    "Evaluate this log likelihood on a grid of b values between 1 and 10. Plot the log likelihood as a function of b."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66e4d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = np.linspace(1, 10, 25) #this is a dense enough grid\n",
    "\n",
    "loglikes = np.zeros_like(bs)\n",
    "\n",
    "for i, b in enumerate(bs):\n",
    "    \n",
    "    loglikes[i] = ?? #complete this\n",
    "    \n",
    "plt.plot(bs, loglikes)\n",
    "\n",
    "#xlabel\n",
    "\n",
    "#ylabel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55434f8",
   "metadata": {},
   "source": [
    "## Problem 5 (10 points):\n",
    "Given a prior $p(b)$, the posterior on $b$ is:\n",
    "$$\n",
    "p(b \\mid \\mathbf{d}) = \\frac{p(\\mathbf{d} \\mid b) p(b) }{\\int p(\\mathbf{d} \\mid b)p(b) db}\n",
    "$$\n",
    "\n",
    "Assume a flat prior $p(b) = constant$. \n",
    "\n",
    "Plot the (normalized) posterior as a function of $b$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011e9f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_unnormalized = np.exp(loglikes)\n",
    "\n",
    "posterior_normalized = posterior_unnormalized / ?? #fill this in\n",
    "\n",
    "plt.plot(bs, posterior_normalized)\n",
    "\n",
    "#xlabel\n",
    "\n",
    "#ylabel\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804166c6",
   "metadata": {},
   "source": [
    "## Problem 6 (10 points)\n",
    "\n",
    "Sample 1000 samples from the posterior on $b$ that you just evaluated in the previous problem using inverse transform sampling.\n",
    "\n",
    "Make a (normalized) histogram of your 1000 samples to check that they are distributed according to the posterior probability density function you plotted above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6e0d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf_posterior = cumtrapz(posterior_normalized, bs, initial = 0) #cumulative density function corresponding to posterior probability density function\n",
    "\n",
    "inverse_cdf = lambda u: np.interp(u, cdf_posterior, bs) #evaluate the inverse cdf function\n",
    "\n",
    "us = ?? #complete this, draw 1000 random samples from uniform distribution between 0 and 1\n",
    "\n",
    "b_post_samples = inverse_cdf(us)\n",
    "\n",
    "\n",
    "##make a histogram of b_post_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e676173",
   "metadata": {},
   "source": [
    "## Problem 7 (5 points)\n",
    "\n",
    "Plot posterior draws of your inferred spin distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35d0f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "spin = np.linspace(0, 1, 100)\n",
    "\n",
    "for b in b_post_samples[0:100]: #use first 100 draws, using all 1,000 is overkill\n",
    "    \n",
    "    spin_dist = ss.beta.pdf(spin, a = 1, b = b)\n",
    "    \n",
    "    plt.plot(spin, spin_dist, alpha = 0.1, c = 'k')\n",
    "    \n",
    "#add xlabel\n",
    "\n",
    "#add ylabel\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
